import streamlit as st
import pandas as pd
import io
import zipfile
import unicodedata
import re
import isodate 
import datetime
from googleapiclient.discovery import build 
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.styles import Alignment, Border, Side, Font, PatternFill
from openpyxl.worksheet.datavalidation import DataValidation

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---

def from_hex_fill(hex_code):
    return PatternFill(start_color=hex_code, end_color=hex_code, fill_type="solid")

def get_display_width(text):
    if not isinstance(text, str):
        text = str(text)
    width = 0
    for char in text:
        if unicodedata.east_asian_width(char) in ('F', 'W', 'A'):
            width += 2
        else:
            width += 1
    return width

def extract_video_id(url):
    """YouTubeã®URLã‹ã‚‰å‹•ç”»IDã‚’æŠ½å‡ºã™ã‚‹"""
    if not isinstance(url, str):
        return None
    patterns = [
        r'(?:v=|\/)([0-9A-Za-z_-]{11}).*',
        r'(?:youtu\.be\/)([0-9A-Za-z_-]{11})',
        r'(?:embed\/)([0-9A-Za-z_-]{11})'
    ]
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None

def fetch_youtube_details(api_key, video_ids):
    """YouTube Data APIã‚’ä½¿ç”¨ã—ã¦å‹•ç”»ã®è©³ç´°ã‚’ä¸€æ‹¬å–å¾—ã™ã‚‹"""
    if not api_key or not video_ids:
        return {}
    
    youtube = build('youtube', 'v3', developerKey=api_key)
    results = {}
    
    chunk_size = 50
    for i in range(0, len(video_ids), chunk_size):
        chunk = video_ids[i:i+chunk_size]
        try:
            request = youtube.videos().list(
                part="contentDetails,status",
                id=",".join(chunk)
            )
            response = request.execute()
            
            for item in response.get("items", []):
                vid = item["id"]
                duration_iso = item["contentDetails"]["duration"]
                privacy_status = item["status"]["privacyStatus"]
                results[vid] = {
                    "duration": duration_iso,
                    "status": privacy_status
                }
        except Exception as e:
            st.error(f"YouTube APIé€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            
    return results

def format_duration(iso_duration):
    """ISO 8601å½¢å¼ã‚’å¤‰æ›"""
    try:
        dur = isodate.parse_duration(iso_duration)
        total_seconds = int(dur.total_seconds())
        minutes = total_seconds // 60
        seconds = total_seconds % 60
        return f"{minutes}åˆ†{seconds}ç§’"
    except:
        return ""

# --- ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª ---

st.set_page_config(page_title="éŒ²ç”»å¯©æŸ»è¡¨ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼", layout="wide")

st.title("ğŸ—‚ï¸ éŒ²ç”»å¯©æŸ»è¡¨ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼")
st.markdown("""
ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸåç°¿Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã€éƒ¨é–€ã”ã¨ã®æ¡ç‚¹ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
**ç‰¹å¾´:**
- YouTube APIé€£æºã«ã‚ˆã‚Šã€å‹•ç”»æ™‚é–“ã¨å†ç”Ÿå¯å¦ï¼ˆå…¬é–‹è¨­å®šï¼‰ã‚’è‡ªå‹•ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚
- è¬›è©•æ¬„ã®æ–‡å­—æ•°è¨­å®šã«å¿œã˜ã¦ãƒ˜ãƒƒãƒ€ãƒ¼ãŒè‡ªå‹•ã§å¤‰ã‚ã‚Šã¾ã™ã€‚
- å‡¦ç†çµæœãƒ­ã‚°ã‚’å«ã‚€ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
""")

# --- APIã‚­ãƒ¼è¨­å®š ---
with st.expander("ğŸ”‘ YouTube APIè¨­å®š (å¿…é ˆ)", expanded=True):
    secret_key = st.secrets.get("YOUTUBE_API_KEY", None)
    user_input_key = st.text_input(
        "YouTube Data APIã‚­ãƒ¼ï¼ˆSecretsè¨­å®šæ¸ˆã¿ã®å ´åˆã¯ç©ºæ¬„ã§OKã§ã™ï¼‰", 
        type="password", 
        help="Google Cloud Consoleã§å–å¾—ã—ãŸAPIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
    )
    final_api_key = user_input_key if user_input_key else secret_key
    
    if user_input_key:
        st.info("â„¹ï¸ å…¥åŠ›ã•ã‚ŒãŸAPIã‚­ãƒ¼ã‚’ä½¿ç”¨ã—ã¾ã™")
    elif secret_key:
        st.success("âœ… Secretsè¨­å®šæ¸ˆã¿ã®APIã‚­ãƒ¼ãŒé©ç”¨ã•ã‚Œã¦ã„ã¾ã™")
    else:
        st.warning("âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å‹•ç”»æƒ…å ±ã®è‡ªå‹•å–å¾—æ©Ÿèƒ½ã¯å‹•ä½œã—ã¾ã›ã‚“ã€‚")

# --- 1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
uploaded_file = st.file_uploader("å‡ºå ´è€…åç°¿ï¼ˆExcelãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["xlsx"])

if uploaded_file:
    try:
        xls = pd.ExcelFile(uploaded_file)
        all_sheets = xls.sheet_names

        st.divider()
        st.subheader("1. å¯¾è±¡ã‚·ãƒ¼ãƒˆã®é¸æŠ")
        
        ignore_keywords = ["åŸæœ¬", "ç·åˆåç°¿", "å‰Šé™¤ãƒ­ã‚°", "ãƒ­ã‚°"]
        default_selections = [s for s in all_sheets if not any(kw in s for kw in ignore_keywords)]
        
        target_sheets = st.multiselect(
            "å¯©æŸ»è¡¨ã‚’ä½œæˆã—ãŸã„ã‚·ãƒ¼ãƒˆï¼ˆéƒ¨é–€ï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„",
            options=all_sheets,
            default=default_selections
        )

        if target_sheets:
            df_sample = pd.read_excel(xls, sheet_name=target_sheets[0])
            source_columns = ["ï¼ˆãªã—ï¼‰"] + list(df_sample.columns)

            st.divider()
            st.subheader("2. åˆ—ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã¨å‡ºåŠ›è¨­å®š")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("##### ğŸ“‹ åˆ—ã®ç´ä»˜ã‘")
                
                def get_index(options, keywords):
                    for i, opt in enumerate(options):
                        for kw in keywords:
                            if kw in opt:
                                return i
                    return 0

                mapping = {}
                mapping["entry_number"] = st.selectbox("å‡ºå ´ç•ªå·", source_columns, index=get_index(source_columns, ["ç•ªå·", "No", "ID"]))
                mapping["entry_name"] = st.selectbox("å‡ºå ´è€…å", source_columns, index=get_index(source_columns, ["æ°å", "åå‰", "å›£ä½“å"]))
                mapping["instrument"] = st.selectbox("æ¥½å™¨å (ä»»æ„)", source_columns, index=get_index(source_columns, ["æ¥½å™¨"]))
                mapping["age"] = st.selectbox("å¹´é½¢", source_columns, index=get_index(source_columns, ["å¹´é½¢", "å­¦å¹´"]))
                mapping["song"] = st.selectbox("æ›²ç›®", source_columns, index=get_index(source_columns, ["æ›²ç›®", "æ›²å"]))
                mapping["youtube"] = st.selectbox("YouTube URL", source_columns, index=get_index(source_columns, ["YouTube", "URL", "å‹•ç”»"]))
                mapping["duration"] = st.selectbox("æ¼”å¥æ™‚é–“ (å…ƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°)", source_columns, index=get_index(source_columns, ["æ™‚é–“", "ã‚¿ã‚¤ãƒ "]))
                # ã€è¿½åŠ ã€‘ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹åˆ—ã®æŒ‡å®š
                mapping["email"] = st.selectbox("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ (ä»»æ„ãƒ»é€£çµ¡ç”¨)", source_columns, index=get_index(source_columns, ["ãƒ¡ãƒ¼ãƒ«", "mail", "Email"]))

            with col2:
                st.markdown("##### âš™ï¸ å¯©æŸ»è¡¨ã®å‡ºåŠ›è¨­å®š")
                
                output_filename_base = st.text_input("å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®åŸºæœ¬å", value="éŒ²ç”»å¯©æŸ»è¡¨")
                score_mode = st.selectbox("æ¡ç‚¹æ–¹å¼", ["æ¡ç‚¹(100ç‚¹æº€ç‚¹)", "æ¡ç‚¹(â—¯â–³âœ•)"])
                score_header_display = "æ¡ç‚¹"
                
                min_char_count = st.number_input("è¬›è©•ã®æœ€ä½æ–‡å­—æ•°ï¼ˆè­¦å‘Šç”¨ï¼‰", min_value=0, value=100, step=10)
                
                if min_char_count > 0:
                    comment_header_text = f"å¯©æŸ»è¬›è©•ï¼ˆ{min_char_count}æ–‡å­—ä»¥ä¸Šï¼‰"
                else:
                    comment_header_text = "å¯©æŸ»è¬›è©•ï¼ˆ100ï½200æ–‡å­—ç¨‹åº¦ä»¥ä¸Šï¼‰"
                
                st.info(f"å‡ºåŠ›ã•ã‚Œã‚‹ãƒ˜ãƒƒãƒ€ãƒ¼å: **{comment_header_text}**")

            # --- å®Ÿè¡Œãƒœã‚¿ãƒ³ ---
            st.divider()
            generate_btn = st.button("å¯©æŸ»è¡¨ã‚’ä½œæˆã™ã‚‹", type="primary")

            if generate_btn:
                if any(mapping[k] == "ï¼ˆãªã—ï¼‰" for k in ["entry_number", "entry_name", "song", "youtube"]):
                    st.error("ã‚¨ãƒ©ãƒ¼: å¿…é ˆé …ç›®ï¼ˆç•ªå·ã€æ°åã€æ›²ç›®ã€URLï¼‰ã«ã¯åˆ—ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
                elif not final_api_key:
                     st.error("ã‚¨ãƒ©ãƒ¼: YouTube APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                else:
                    output_files = {}
                    error_logs_list = [] # æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ç”¨
                    progress_bar = st.progress(0)
                    
                    try:
                        total_sheets = len(target_sheets)
                        
                        for i, sheet_name in enumerate(target_sheets):
                            df = pd.read_excel(xls, sheet_name=sheet_name)
                            
                            missing_cols = []
                            for k, v in mapping.items():
                                if v != "ï¼ˆãªã—ï¼‰" and v not in df.columns:
                                    missing_cols.append(v)
                            
                            if missing_cols:
                                st.warning(f"ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ã«ã¯ä»¥ä¸‹ã®åˆ—ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ: {', '.join(missing_cols)}")
                                continue

                            # YouTube APIå‡¦ç†
                            id_map = {} 
                            if mapping["youtube"] != "ï¼ˆãªã—ï¼‰":
                                for idx, row in df.iterrows():
                                    url = row[mapping["youtube"]]
                                    vid = extract_video_id(url)
                                    if vid:
                                        id_map[idx] = vid
                            
                            unique_ids = list(set(id_map.values()))
                            api_results = fetch_youtube_details(final_api_key, unique_ids)
                            
                            new_data = []
                            for idx, row in df.iterrows():
                                num_val = row[mapping["entry_number"]] if mapping["entry_number"] != "ï¼ˆãªã—ï¼‰" else ""
                                name_val = row[mapping["entry_name"]] if mapping["entry_name"] != "ï¼ˆãªã—ï¼‰" else ""
                                youtube_url = row[mapping["youtube"]] if mapping["youtube"] != "ï¼ˆãªã—ï¼‰" else ""
                                email_val = row[mapping["email"]] if mapping["email"] != "ï¼ˆãªã—ï¼‰" else "ä¸æ˜"
                                
                                duration_text = ""
                                if mapping["duration"] != "ï¼ˆãªã—ï¼‰":
                                    duration_text = row[mapping["duration"]]

                                # æ–°è¨­åˆ—ã€Œå‹•ç”»ã€ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå†ç”Ÿï¼‰
                                video_link_text = "å†ç”Ÿ" if youtube_url and str(youtube_url).lower() != "nan" else ""

                                # APIçµæœãƒã‚§ãƒƒã‚¯
                                if idx in id_map:
                                    vid = id_map[idx]
                                    if vid in api_results:
                                        details = api_results[vid]
                                        status = details["status"]
                                        
                                        if status in ['public', 'unlisted']:
                                            duration_text = format_duration(details["duration"])
                                        else:
                                            error_msg = f"å‹•ç”»è¨­å®šãŒã€Œ{status}ã€ã®ãŸã‚å†ç”Ÿã§ãã¾ã›ã‚“"
                                            # ãƒ­ã‚°ã«è¿½åŠ ï¼ˆæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ï¼‰
                                            error_logs_list.append({
                                                "type": "error",
                                                "dept": sheet_name,
                                                "no": num_val,
                                                "name": name_val,
                                                "reason": error_msg,
                                                "url": youtube_url,
                                                "email": email_val
                                            })
                                            duration_text = "ã€å†ç”Ÿä¸å¯ã€‘è¦ç¢ºèª"
                                    else:
                                        error_msg = "å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆå‰Šé™¤ã¾ãŸã¯IDç„¡åŠ¹ï¼‰"
                                        error_logs_list.append({
                                                "type": "error",
                                                "dept": sheet_name,
                                                "no": num_val,
                                                "name": name_val,
                                                "reason": error_msg,
                                                "url": youtube_url,
                                                "email": email_val
                                            })
                                        duration_text = "ã€ç„¡åŠ¹ã€‘è¦ç¢ºèª"
                                elif youtube_url and not str(youtube_url).lower() == "nan":
                                    error_msg = "URLã®å½¢å¼ãŒä¸æ˜ã§ã™"
                                    error_logs_list.append({
                                                "type": "error",
                                                "dept": sheet_name,
                                                "no": num_val,
                                                "name": name_val,
                                                "reason": error_msg,
                                                "url": youtube_url,
                                                "email": email_val
                                            })
                                
                                # DataFrameæ§‹ç¯‰
                                record = {
                                    "å‡ºå ´éƒ¨é–€": sheet_name,
                                    "å‡ºå ´ç•ªå·": num_val,
                                    "å‡ºå ´è€…å": name_val,
                                    "å¹´é½¢": row[mapping["age"]] if mapping["age"] != "ï¼ˆãªã—ï¼‰" else "",
                                    "æ›²ç›®": row[mapping["song"]] if mapping["song"] != "ï¼ˆãªã—ï¼‰" else "",
                                    "å‹•ç”»": video_link_text, # æ–°è¨­
                                    "YouTube URL": youtube_url, # éè¡¨ç¤ºã«ã™ã‚‹åˆ—
                                    "æ¼”å¥æ™‚é–“": duration_text,
                                }
                                if mapping["instrument"] != "ï¼ˆãªã—ï¼‰":
                                    record["æ¥½å™¨å"] = row[mapping["instrument"]]
                                
                                record[score_header_display] = ""
                                record[comment_header_text] = ""
                                
                                new_data.append(record)
                            
                            df_out = pd.DataFrame(new_data)
                            
                            # åˆ—é †åº: YouTube URL ã¯ å‹•ç”» ã®å³éš£ï¼ˆéè¡¨ç¤ºã«ã™ã‚‹ï¼‰
                            cols_order = ["å‡ºå ´éƒ¨é–€"]
                            if mapping["instrument"] != "ï¼ˆãªã—ï¼‰":
                                cols_order.append("æ¥½å™¨å")
                            # å‹•ç”»åˆ—ã¨URLåˆ—ã‚’é…ç½®
                            cols_order.extend(["å‡ºå ´ç•ªå·", "å‡ºå ´è€…å", "å¹´é½¢", "æ›²ç›®", "å‹•ç”»", "YouTube URL", "æ¼”å¥æ™‚é–“", score_header_display, comment_header_text])
                            
                            final_cols = [c for c in cols_order if c in df_out.columns]
                            df_out = df_out[final_cols]

                            wb = Workbook()
                            ws = wb.active
                            ws.title = "å¯©æŸ»è¡¨"

                            for r_idx, row in enumerate(dataframe_to_rows(df_out, index=False, header=True), 1):
                                # è¡Œã®é«˜ã•è‡ªå‹•èª¿æ•´
                                if r_idx > 1:
                                    max_lines = 1
                                    for val in row:
                                        val_str = str(val) if val is not None else ""
                                        lines = val_str.count('\n') + 1
                                        if lines > max_lines:
                                            max_lines = lines
                                    row_height = max(30, max_lines * 15)
                                    ws.row_dimensions[r_idx].height = row_height

                                for c_idx, value in enumerate(row, 1):
                                    cell = ws.cell(row=r_idx, column=c_idx, value=value)
                                    col_name = df_out.columns[c_idx - 1]
                                    
                                    thin = Side(border_style="thin", color="000000")
                                    cell.border = Border(top=thin, left=thin, right=thin, bottom=thin)

                                    if r_idx == 1: 
                                        cell.font = Font(bold=True, color="FFFFFF")
                                        cell.fill = from_hex_fill("4F81BD")
                                        cell.alignment = Alignment(horizontal="left", vertical="center")
                                    else: 
                                        align_h = "center" if col_name in ["å¹´é½¢", "å‹•ç”»", score_header_display] else "left"
                                        cell.alignment = Alignment(horizontal=align_h, vertical="center", wrap_text=True)
                                        
                                        # ã€æ–°æ©Ÿèƒ½ã€‘ã€Œå‹•ç”»ã€åˆ—ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯è¨­å®š
                                        if col_name == "å‹•ç”»" and value == "å†ç”Ÿ":
                                            # éš£ï¼ˆã¾ãŸã¯è¿‘ãï¼‰ã®YouTube URLåˆ—ã‹ã‚‰URLã‚’å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
                                            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®åŒã˜è¡Œã‚’å‚ç…§ã™ã‚‹
                                            # df_outã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯ r_idx-2
                                            url_val = df_out.iloc[r_idx-2]["YouTube URL"]
                                            if url_val and str(url_val).lower() != "nan":
                                                cell.hyperlink = url_val
                                                cell.font = Font(color="0563C1", underline="single")
                                        
                                        # æ¼”å¥æ™‚é–“ã®ã‚¨ãƒ©ãƒ¼å¼·èª¿
                                        if col_name == "æ¼”å¥æ™‚é–“" and ("ã€" in str(value) or "ç¢ºèª" in str(value)):
                                            cell.font = Font(color="FF0000", bold=True)

                            # åˆ—å¹…ã¨éè¡¨ç¤ºè¨­å®š
                            for i_col, col_name in enumerate(final_cols):
                                column_letter = ws.cell(row=1, column=i_col+1).column_letter
                                
                                # ã€å¤‰æ›´ã€‘YouTube URLåˆ—ã¯éè¡¨ç¤ºã«ã™ã‚‹
                                if col_name == "YouTube URL":
                                    ws.column_dimensions[column_letter].hidden = True
                                    continue # å¹…è¨­å®šä¸è¦
                                
                                if col_name == "å‡ºå ´ç•ªå·":
                                    ws.column_dimensions[column_letter].width = 12
                                elif col_name == "å¹´é½¢":
                                    ws.column_dimensions[column_letter].width = 8
                                elif col_name == "å‹•ç”»": # æ–°è¨­åˆ—
                                    ws.column_dimensions[column_letter].width = 8
                                elif col_name == comment_header_text:
                                    ws.column_dimensions[column_letter].width = 50
                                elif col_name == score_header_display:
                                    ws.column_dimensions[column_letter].width = 10
                                else:
                                    # ã€å¤‰æ›´ã€‘ä½™ç™½è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯: æœ€å¤§æ–‡å­—æ•° + 2 (å…¨è§’1æ–‡å­—åˆ†)
                                    data_lengths = [get_display_width(str(val)) for val in df_out[col_name].fillna("")]
                                    if data_lengths:
                                        max_len = max(data_lengths)
                                        # å›ºå®šåŠ ç®—æ–¹å¼ã«å¤‰æ›´
                                        calc_width = max_len + 3 
                                        limit_width = 80
                                        final_width = max(min(calc_width, limit_width), 10)
                                        ws.column_dimensions[column_letter].width = final_width
                                    else:
                                        ws.column_dimensions[column_letter].width = 20

                            # å…¥åŠ›è¦å‰‡
                            comment_col_idx = None
                            for cell in ws[1]:
                                if cell.value == comment_header_text:
                                    comment_col_idx = cell.column_letter
                                    break
                            
                            if min_char_count > 0 and comment_col_idx:
                                formula = f'LEN({comment_col_idx}2)>={min_char_count}'
                                dv = DataValidation(
                                    type="custom",
                                    formula1=formula,
                                    allow_blank=True,
                                    showErrorMessage=True,
                                    errorTitle="å…¥åŠ›æ–‡å­—æ•°ä¸è¶³",
                                    error="å¯©æŸ»è¬›è©•ã¯æŒ‡å®šã•ã‚ŒãŸæ–‡å­—æ•°ä»¥ä¸Šå…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
                                )
                                dv.add(f"{comment_col_idx}2:{comment_col_idx}{len(df_out)+1}")
                                ws.add_data_validation(dv)

                            excel_buffer = io.BytesIO()
                            wb.save(excel_buffer)
                            excel_buffer.seek(0)
                            
                            output_files[f"{output_filename_base}_{sheet_name}.xlsx"] = excel_buffer
                            progress_val = min((i + 1) / total_sheets, 1.0)
                            progress_bar.progress(progress_val)

                        # --- ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ (ä½“è£ã‚’æ•´ãˆã‚‹) ---
                        
                        log_lines = []
                        log_lines.append("ã€å†ç”Ÿå¯å¦åˆ¤å®šãƒ¬ãƒãƒ¼ãƒˆã€‘")
                        log_lines.append(f"ç¢ºèªæ—¥æ™‚: {datetime.datetime.now().strftime('%Y/%m/%d %H:%M')}")
                        log_lines.append("\n" + "-"*50)
                        log_lines.append("âš ï¸ è¦ç¢ºèªï¼ˆå†ç”Ÿä¸å¯ãªã©ï¼‰")
                        log_lines.append("-"*50 + "\n")
                        
                        if error_logs_list:
                            for log in error_logs_list:
                                log_lines.append(f"[{log['dept']}] {log['no']} {log['name']} æ§˜")
                                log_lines.append(f"çŠ¶æ³: {log['reason']}")
                                log_lines.append(f"URL : {log['url']}")
                                log_lines.append(f"Email: {log['email']}")
                                log_lines.append("") # ç©ºè¡Œ
                        else:
                            log_lines.append("ï¼ˆè©²å½“ãªã—ã€‚ã™ã¹ã¦ã®å‹•ç”»ãŒæ­£å¸¸ã«ç¢ºèªã•ã‚Œã¾ã—ãŸï¼‰\n")
                            
                        log_lines.append("\n" + "-"*50)
                        log_lines.append("âœ… ç¢ºèªå®Œäº†")
                        log_lines.append("-"*50)
                        log_lines.append("ä¸Šè¨˜ä»¥å¤–ã®å‹•ç”»ã«ã¤ã„ã¦ã¯ã€æ­£å¸¸ã«æ™‚é–“å–å¾—ãŒå®Œäº†ã—ã¦ã„ã¾ã™ã€‚")

                        log_content = "\n".join(log_lines)
                        
                        # ãƒ•ã‚¡ã‚¤ãƒ«åå¤‰æ›´: å†ç”Ÿå¯å¦åˆ¤å®š.txt
                        log_buffer = io.BytesIO()
                        log_buffer.write(log_content.encode('utf-8-sig'))
                        log_buffer.seek(0)
                        output_files["å†ç”Ÿå¯å¦åˆ¤å®š.txt"] = log_buffer

                        st.success("ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                        
                        zip_buffer = io.BytesIO()
                        with zipfile.ZipFile(zip_buffer, "w") as zf:
                            for fname, fbuff in output_files.items():
                                zf.writestr(fname, fbuff.getvalue())
                        zip_buffer.seek(0)
                        
                        st.download_button(
                            label="ğŸ“¥ å¯©æŸ»è¡¨ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ZIP)",
                            data=zip_buffer,
                            file_name=f"{output_filename_base}_ã‚»ãƒƒãƒˆ.zip",
                            mime="application/zip"
                        )
                        
                        if error_logs_list:
                            st.error(f"âš ï¸ {len(error_logs_list)}ä»¶ã®å‹•ç”»ã«å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚è©³ç´°ã¯ã€Œå†ç”Ÿå¯å¦åˆ¤å®š.txtã€ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
                            # ç°¡æ˜“è¡¨ç¤º
                            simple_log = "\n".join([f"[{l['dept']}] {l['name']}: {l['reason']}" for l in error_logs_list])
                            st.text_area("ã‚¨ãƒ©ãƒ¼è©³ç´°ãƒ­ã‚°ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰", value=simple_log, height=150)

                    except Exception as e:
                        st.error(f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
