import streamlit as st
import pandas as pd
import io
import zipfile
import unicodedata
import re
import isodate # YouTubeã®æ™‚é–“å½¢å¼å¤‰æ›ç”¨
from googleapiclient.discovery import build # YouTube APIç”¨
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.styles import Alignment, Border, Side, Font, PatternFill
from openpyxl.worksheet.datavalidation import DataValidation

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---

def from_hex_fill(hex_code):
    return PatternFill(start_color=hex_code, end_color=hex_code, fill_type="solid")

def get_display_width(text):
    if not isinstance(text, str):
        text = str(text)
    width = 0
    for char in text:
        if unicodedata.east_asian_width(char) in ('F', 'W', 'A'):
            width += 2
        else:
            width += 1
    return width

def extract_video_id(url):
    """YouTubeã®URLã‹ã‚‰å‹•ç”»IDã‚’æŠ½å‡ºã™ã‚‹"""
    if not isinstance(url, str):
        return None
    patterns = [
        r'(?:v=|\/)([0-9A-Za-z_-]{11}).*',
        r'(?:youtu\.be\/)([0-9A-Za-z_-]{11})',
        r'(?:embed\/)([0-9A-Za-z_-]{11})'
    ]
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None

def fetch_youtube_details(api_key, video_ids):
    """YouTube Data APIã‚’ä½¿ç”¨ã—ã¦å‹•ç”»ã®è©³ç´°ã‚’ä¸€æ‹¬å–å¾—ã™ã‚‹"""
    if not api_key or not video_ids:
        return {}
    
    youtube = build('youtube', 'v3', developerKey=api_key)
    results = {}
    
    chunk_size = 50
    for i in range(0, len(video_ids), chunk_size):
        chunk = video_ids[i:i+chunk_size]
        try:
            request = youtube.videos().list(
                part="contentDetails,status",
                id=",".join(chunk)
            )
            response = request.execute()
            
            for item in response.get("items", []):
                vid = item["id"]
                duration_iso = item["contentDetails"]["duration"]
                privacy_status = item["status"]["privacyStatus"]
                results[vid] = {
                    "duration": duration_iso,
                    "status": privacy_status
                }
        except Exception as e:
            st.error(f"YouTube APIé€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            
    return results

def format_duration(iso_duration):
    """ISO 8601å½¢å¼ã‚’å¤‰æ›"""
    try:
        dur = isodate.parse_duration(iso_duration)
        total_seconds = int(dur.total_seconds())
        minutes = total_seconds // 60
        seconds = total_seconds % 60
        return f"{minutes}åˆ†{seconds}ç§’"
    except:
        return ""

# --- ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª ---

st.set_page_config(page_title="éŒ²ç”»å¯©æŸ»è¡¨ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼", layout="wide")

st.title("ğŸ—‚ï¸ éŒ²ç”»å¯©æŸ»è¡¨ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼")
st.markdown("""
ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸåç°¿Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã€éƒ¨é–€ã”ã¨ã®æ¡ç‚¹ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
**ç‰¹å¾´:**
- YouTube APIé€£æºã«ã‚ˆã‚Šã€å‹•ç”»æ™‚é–“ã¨å†ç”Ÿå¯å¦ï¼ˆå…¬é–‹è¨­å®šï¼‰ã‚’è‡ªå‹•ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚
- è¬›è©•æ¬„ã®æ–‡å­—æ•°è¨­å®šã«å¿œã˜ã¦ãƒ˜ãƒƒãƒ€ãƒ¼ãŒè‡ªå‹•ã§å¤‰ã‚ã‚Šã¾ã™ã€‚
""")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã¾ãŸã¯ä¸Šéƒ¨ã§ã®APIã‚­ãƒ¼å…¥åŠ›ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ç‰ˆï¼‰ ---
with st.expander("ğŸ”‘ YouTube APIè¨­å®š (å¿…é ˆ)", expanded=True):
    # Secretsã‹ã‚‰ã‚­ãƒ¼ã‚’å–å¾—ï¼ˆç”»é¢ã«ã¯å‡ºã•ãªã„ï¼‰
    secret_key = st.secrets.get("YOUTUBE_API_KEY", None)
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›æ¬„ï¼ˆåˆæœŸå€¤ã¯ç©ºï¼‰
    user_input_key = st.text_input(
        "YouTube Data APIã‚­ãƒ¼ï¼ˆSecretsè¨­å®šæ¸ˆã¿ã®å ´åˆã¯ç©ºæ¬„ã§OKã§ã™ï¼‰", 
        type="password", 
        help="Google Cloud Consoleã§å–å¾—ã—ãŸAPIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
    )
    
    # æœ€çµ‚çš„ã«ä½¿ç”¨ã™ã‚‹ã‚­ãƒ¼ã‚’æ±ºå®šï¼ˆå…¥åŠ›ãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆã€ãªã‘ã‚Œã°Secretsã‚’ä½¿ã†ï¼‰
    final_api_key = user_input_key if user_input_key else secret_key
    
    # çŠ¶æ…‹è¡¨ç¤º
    if user_input_key:
        st.info("â„¹ï¸ å…¥åŠ›ã•ã‚ŒãŸAPIã‚­ãƒ¼ã‚’ä½¿ç”¨ã—ã¾ã™")
    elif secret_key:
        st.success("âœ… Secretsè¨­å®šæ¸ˆã¿ã®APIã‚­ãƒ¼ãŒé©ç”¨ã•ã‚Œã¦ã„ã¾ã™ï¼ˆç”»é¢ã«ã¯è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ï¼‰")
    else:
        st.warning("âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å‹•ç”»æƒ…å ±ã®è‡ªå‹•å–å¾—æ©Ÿèƒ½ã¯å‹•ä½œã—ã¾ã›ã‚“ã€‚")

# --- 1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
uploaded_file = st.file_uploader("å‡ºå ´è€…åç°¿ï¼ˆExcelãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["xlsx"])

if uploaded_file:
    try:
        xls = pd.ExcelFile(uploaded_file)
        all_sheets = xls.sheet_names

        st.divider()
        st.subheader("1. å¯¾è±¡ã‚·ãƒ¼ãƒˆã®é¸æŠ")
        
        target_sheets = st.multiselect(
            "å¯©æŸ»è¡¨ã‚’ä½œæˆã—ãŸã„ã‚·ãƒ¼ãƒˆï¼ˆéƒ¨é–€ï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„",
            options=all_sheets,
            default=[s for s in all_sheets if "ãƒ­ã‚°" not in s] 
        )

        if target_sheets:
            df_sample = pd.read_excel(xls, sheet_name=target_sheets[0])
            source_columns = ["ï¼ˆãªã—ï¼‰"] + list(df_sample.columns)

            st.divider()
            st.subheader("2. åˆ—ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã¨å‡ºåŠ›è¨­å®š")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("##### ğŸ“‹ åˆ—ã®ç´ä»˜ã‘")
                
                def get_index(options, keywords):
                    for i, opt in enumerate(options):
                        for kw in keywords:
                            if kw in opt:
                                return i
                    return 0

                mapping = {}
                mapping["entry_number"] = st.selectbox("å‡ºå ´ç•ªå·", source_columns, index=get_index(source_columns, ["ç•ªå·", "No", "ID"]))
                mapping["entry_name"] = st.selectbox("å‡ºå ´è€…å", source_columns, index=get_index(source_columns, ["æ°å", "åå‰", "å›£ä½“å"]))
                mapping["instrument"] = st.selectbox("æ¥½å™¨å (ä»»æ„)", source_columns, index=get_index(source_columns, ["æ¥½å™¨"]))
                mapping["age"] = st.selectbox("å¹´é½¢", source_columns, index=get_index(source_columns, ["å¹´é½¢", "å­¦å¹´"]))
                mapping["song"] = st.selectbox("æ›²ç›®", source_columns, index=get_index(source_columns, ["æ›²ç›®", "æ›²å"]))
                mapping["youtube"] = st.selectbox("YouTube URL", source_columns, index=get_index(source_columns, ["YouTube", "URL", "å‹•ç”»"]))
                mapping["duration"] = st.selectbox("æ¼”å¥æ™‚é–“ (å…ƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°)", source_columns, index=get_index(source_columns, ["æ™‚é–“", "ã‚¿ã‚¤ãƒ "]))

            with col2:
                st.markdown("##### âš™ï¸ å¯©æŸ»è¡¨ã®å‡ºåŠ›è¨­å®š")
                
                output_filename_base = st.text_input("å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®åŸºæœ¬å", value="éŒ²ç”»å¯©æŸ»è¡¨")
                score_mode = st.selectbox("æ¡ç‚¹æ–¹å¼", ["æ¡ç‚¹(100ç‚¹æº€ç‚¹)", "æ¡ç‚¹(â—¯â–³âœ•)"])
                score_header_display = "æ¡ç‚¹"
                
                min_char_count = st.number_input("è¬›è©•ã®æœ€ä½æ–‡å­—æ•°ï¼ˆè­¦å‘Šç”¨ï¼‰", min_value=0, value=100, step=10)
                
                if min_char_count > 0:
                    comment_header_text = f"å¯©æŸ»è¬›è©•ï¼ˆ{min_char_count}æ–‡å­—ä»¥ä¸Šï¼‰"
                else:
                    comment_header_text = "å¯©æŸ»è¬›è©•ï¼ˆ100ï½200æ–‡å­—ç¨‹åº¦ä»¥ä¸Šï¼‰"
                
                st.info(f"å‡ºåŠ›ã•ã‚Œã‚‹ãƒ˜ãƒƒãƒ€ãƒ¼å: **{comment_header_text}**")

            # --- å®Ÿè¡Œãƒœã‚¿ãƒ³ ---
            st.divider()
            generate_btn = st.button("å¯©æŸ»è¡¨ã‚’ä½œæˆã™ã‚‹", type="primary")

            if generate_btn:
                # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
                required_fields = ["entry_number", "entry_name", "song", "youtube"]
                if any(mapping[k] == "ï¼ˆãªã—ï¼‰" for k in required_fields):
                    st.error("ã‚¨ãƒ©ãƒ¼: å¿…é ˆé …ç›®ï¼ˆç•ªå·ã€æ°åã€æ›²ç›®ã€URLï¼‰ã«ã¯åˆ—ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
                elif not final_api_key: # ã“ã“ã§ä½¿ç”¨ã™ã‚‹å¤‰æ•°ã‚’å¤‰æ›´
                     st.error("ã‚¨ãƒ©ãƒ¼: YouTube APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Secretsã‚’è¨­å®šã™ã‚‹ã‹å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                else:
                    # å‡¦ç†é–‹å§‹
                    output_files = {}
                    error_logs = [] 
                    progress_bar = st.progress(0)
                    
                    try:
                        total_sheets = len(target_sheets)
                        
                        for i, sheet_name in enumerate(target_sheets):
                            df = pd.read_excel(xls, sheet_name=sheet_name)
                            
                            missing_cols = []
                            for k, v in mapping.items():
                                if v != "ï¼ˆãªã—ï¼‰" and v not in df.columns:
                                    missing_cols.append(v)
                            
                            if missing_cols:
                                st.warning(f"ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ã«ã¯ä»¥ä¸‹ã®åˆ—ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ: {', '.join(missing_cols)}")
                                continue

                            # YouTube APIã«ã‚ˆã‚‹æƒ…å ±å–å¾—
                            id_map = {} 
                            if mapping["youtube"] != "ï¼ˆãªã—ï¼‰":
                                for idx, row in df.iterrows():
                                    url = row[mapping["youtube"]]
                                    vid = extract_video_id(url)
                                    if vid:
                                        id_map[idx] = vid
                            
                            unique_ids = list(set(id_map.values()))
                            # ã“ã“ã§ä½¿ç”¨ã™ã‚‹å¤‰æ•°ã‚’ final_api_key ã«å¤‰æ›´
                            api_results = fetch_youtube_details(final_api_key, unique_ids)
                            
                            new_data = []
                            for idx, row in df.iterrows():
                                num_val = row[mapping["entry_number"]] if mapping["entry_number"] != "ï¼ˆãªã—ï¼‰" else ""
                                name_val = row[mapping["entry_name"]] if mapping["entry_name"] != "ï¼ˆãªã—ï¼‰" else ""
                                youtube_url = row[mapping["youtube"]] if mapping["youtube"] != "ï¼ˆãªã—ï¼‰" else ""
                                
                                duration_text = ""
                                if mapping["duration"] != "ï¼ˆãªã—ï¼‰":
                                    duration_text = row[mapping["duration"]]

                                if idx in id_map:
                                    vid = id_map[idx]
                                    if vid in api_results:
                                        details = api_results[vid]
                                        status = details["status"]
                                        
                                        if status in ['public', 'unlisted']:
                                            duration_text = format_duration(details["duration"])
                                        else:
                                            error_msg = f"å‹•ç”»è¨­å®šãŒã€Œ{status}ã€ã®ãŸã‚å†ç”Ÿã§ãã¾ã›ã‚“"
                                            error_logs.append(f"[{sheet_name}] [{num_val}] {name_val} : {error_msg} ({youtube_url})")
                                            duration_text = "ã€å†ç”Ÿä¸å¯ã€‘è¦ç¢ºèª"
                                    else:
                                        error_msg = "å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆå‰Šé™¤ã¾ãŸã¯IDç„¡åŠ¹ï¼‰"
                                        error_logs.append(f"[{sheet_name}] [{num_val}] {name_val} : {error_msg} ({youtube_url})")
                                        duration_text = "ã€ç„¡åŠ¹ã€‘è¦ç¢ºèª"
                                elif youtube_url and not str(youtube_url).lower() == "nan":
                                    error_msg = "URLã®å½¢å¼ãŒä¸æ˜ã§ã™"
                                    error_logs.append(f"[{sheet_name}] [{num_val}] {name_val} : {error_msg} ({youtube_url})")
                                
                                record = {
                                    "å‡ºå ´éƒ¨é–€": sheet_name,
                                    "å‡ºå ´ç•ªå·": num_val,
                                    "å‡ºå ´è€…å": name_val,
                                    "å¹´é½¢": row[mapping["age"]] if mapping["age"] != "ï¼ˆãªã—ï¼‰" else "",
                                    "æ›²ç›®": row[mapping["song"]] if mapping["song"] != "ï¼ˆãªã—ï¼‰" else "",
                                    "YouTube URL": youtube_url,
                                    "æ¼”å¥æ™‚é–“": duration_text,
                                }
                                if mapping["instrument"] != "ï¼ˆãªã—ï¼‰":
                                    record["æ¥½å™¨å"] = row[mapping["instrument"]]
                                
                                record[score_header_display] = ""
                                record[comment_header_text] = ""
                                
                                new_data.append(record)
                            
                            df_out = pd.DataFrame(new_data)
                            
                            cols_order = ["å‡ºå ´éƒ¨é–€"]
                            if mapping["instrument"] != "ï¼ˆãªã—ï¼‰":
                                cols_order.append("æ¥½å™¨å")
                            cols_order.extend(["å‡ºå ´ç•ªå·", "å‡ºå ´è€…å", "å¹´é½¢", "æ›²ç›®", "YouTube URL", "æ¼”å¥æ™‚é–“", score_header_display, comment_header_text])
                            
                            final_cols = [c for c in cols_order if c in df_out.columns]
                            df_out = df_out[final_cols]

                            wb = Workbook()
                            ws = wb.active
                            ws.title = "å¯©æŸ»è¡¨"

                            for r_idx, row in enumerate(dataframe_to_rows(df_out, index=False, header=True), 1):
                                if r_idx > 1:
                                    ws.row_dimensions[r_idx].height = 30 

                                for c_idx, value in enumerate(row, 1):
                                    cell = ws.cell(row=r_idx, column=c_idx, value=value)
                                    col_name = df_out.columns[c_idx - 1]
                                    
                                    thin = Side(border_style="thin", color="000000")
                                    cell.border = Border(top=thin, left=thin, right=thin, bottom=thin)

                                    if r_idx == 1: 
                                        cell.font = Font(bold=True, color="FFFFFF")
                                        cell.fill = from_hex_fill("4F81BD")
                                        cell.alignment = Alignment(horizontal="left", vertical="center")
                                    else: 
                                        align_h = "center" if col_name in ["å¹´é½¢", score_header_display] else "left"
                                        cell.alignment = Alignment(horizontal=align_h, vertical="center", wrap_text=True)

                                        if col_name == "YouTube URL" and value:
                                            cell.hyperlink = value
                                            cell.font = Font(color="0563C1", underline="single")
                                        
                                        if col_name == "æ¼”å¥æ™‚é–“" and ("ã€" in str(value) or "ç¢ºèª" in str(value)):
                                            cell.font = Font(color="FF0000", bold=True)

                            for i_col, col_name in enumerate(final_cols):
                                column_letter = ws.cell(row=1, column=i_col+1).column_letter
                                
                                if col_name == "å‡ºå ´ç•ªå·":
                                    ws.column_dimensions[column_letter].width = 12
                                elif col_name == "å¹´é½¢":
                                    ws.column_dimensions[column_letter].width = 8
                                elif col_name == comment_header_text:
                                    ws.column_dimensions[column_letter].width = 50
                                elif col_name == score_header_display:
                                    ws.column_dimensions[column_letter].width = 10
                                else:
                                    data_lengths = [get_display_width(str(val)) for val in df_out[col_name].fillna("")]
                                    if data_lengths:
                                        max_len = max(data_lengths)
                                        calc_width = (max_len * 1.1) + 2
                                        limit_width = 80
                                        final_width = max(min(calc_width, limit_width), 15)
                                        ws.column_dimensions[column_letter].width = final_width
                                    else:
                                        ws.column_dimensions[column_letter].width = 20

                            comment_col_idx = None
                            for cell in ws[1]:
                                if cell.value == comment_header_text:
                                    comment_col_idx = cell.column_letter
                                    break
                            
                            if min_char_count > 0 and comment_col_idx:
                                formula = f'LEN({comment_col_idx}2)>={min_char_count}'
                                dv = DataValidation(
                                    type="custom",
                                    formula1=formula,
                                    allow_blank=True,
                                    showErrorMessage=True,
                                    errorTitle="å…¥åŠ›æ–‡å­—æ•°ä¸è¶³",
                                    error="å¯©æŸ»è¬›è©•ã¯æŒ‡å®šã•ã‚ŒãŸæ–‡å­—æ•°ä»¥ä¸Šå…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
                                )
                                dv.add(f"{comment_col_idx}2:{comment_col_idx}{len(df_out)+1}")
                                ws.add_data_validation(dv)

                            excel_buffer = io.BytesIO()
                            wb.save(excel_buffer)
                            excel_buffer.seek(0)
                            
                            output_files[f"{output_filename_base}_{sheet_name}.xlsx"] = excel_buffer
                            
                            progress_val = min((i + 1) / total_sheets, 1.0)
                            progress_bar.progress(progress_val)

                        st.success("ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")

                        if error_logs:
                            st.error(f"âš ï¸ {len(error_logs)}ä»¶ã®å‹•ç”»ã«å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼ˆéå…¬é–‹ã€å‰Šé™¤ãªã©ï¼‰ã€‚ä»¥ä¸‹ã®ãƒªã‚¹ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                            log_text = "\n".join(error_logs)
                            st.text_area("ã‚¨ãƒ©ãƒ¼è©³ç´°ãƒ­ã‚°ï¼ˆå…¨é¸æŠã—ã¦ã‚³ãƒ”ãƒ¼ã§ãã¾ã™ï¼‰", value=log_text, height=200)
                        
                        if len(output_files) == 1:
                            filename, buffer = list(output_files.items())[0]
                            st.download_button(
                                label=f"ğŸ“¥ {filename} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=buffer,
                                file_name=filename,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                        elif len(output_files) > 1:
                            zip_buffer = io.BytesIO()
                            with zipfile.ZipFile(zip_buffer, "w") as zf:
                                for fname, fbuff in output_files.items():
                                    zf.writestr(fname, fbuff.getvalue())
                            zip_buffer.seek(0)
                            
                            st.download_button(
                                label="ğŸ“¥ ã¾ã¨ã‚ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ZIP)",
                                data=zip_buffer,
                                file_name=f"{output_filename_base}_ä¸€æ‹¬å‡ºåŠ›.zip",
                                mime="application/zip"
                            )

                    except Exception as e:
                        st.error(f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
